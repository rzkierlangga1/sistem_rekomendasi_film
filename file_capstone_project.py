# -*- coding: utf-8 -*-
"""File_Capstone_Project (2.0).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h-v1uTdoWiyK4zbelMfOVfffY7FPV40A

##**Import Libraries**
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from collections import Counter
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import pickle
import json

"""## **1. Data Understanding**

### **Data Loading**
"""

# Load dataset
url = "https://raw.githubusercontent.com/ilyasbrhm/Dataset/refs/heads/main/tmdb_dataset.csv"

# Membaca dataset sebagai dataframe
dataset_movies = pd.read_csv(url)

"""###**Data Exploration**"""

# Menampilkan 5 data teratas
dataset_movies.head()

# Melihat jumlah baris dan kolom
print("Jumlah Baris dan Kolom")
print(dataset_movies.shape)

# Melihat jenis data
print("Jenis Data:")
print(dataset_movies.dtypes)

# Tambahkan kolom movie_id dari 1 sampai jumlah data
dataset_movies['movie_id'] = range(1, len(dataset_movies) + 1)

# Pindahkan movie_id ke kolom paling kiri
cols = ['movie_id'] + [col for col in dataset_movies.columns if col != 'movie_id']
dataset_movies = dataset_movies[cols]

dataset_movies.dtypes

"""### **Data Cleaning**"""

# Memeriksa missing values
print("Data yang Hilang")
print(dataset_movies.isnull().sum())

# Membersihkan missing values
df_cleaned = dataset_movies.dropna(subset=['poster_url'])
print(df_cleaned.isnull().sum())

# Membersihkan data duplicates
df_cleaned = df_cleaned.drop_duplicates()

# Cek jumlah data setelah hapus duplikat
print(f"Jumlah data setelah hapus duplikat: {df_cleaned.shape[0]}")

# Mengubah isi kolom genres dari string berbentuk list ke list Python asli
df_cleaned['genre_clean'] = df_cleaned['genres'].apply(lambda x: eval(x) if isinstance(x, str) else [])

# Pecah semua genre jadi satu list besar
all_genres = [genre.strip() for sublist in df_cleaned['genre_clean'] for genre in sublist]

# Hitung jumlah kemunculan tiap genre
genre_count = Counter(all_genres)

# Konversi ke DataFrame dan urutkan
genre_df = pd.DataFrame(genre_count.items(), columns=['Genre', 'Jumlah']).sort_values(by='Jumlah', ascending=False)

# Dataframe hasil hitungan Counter yang menunjukkan jumlah film dari setiap genre
genre_df

# Menampilkandf_cleaned_cleaned (dataframe yang sudah dibersihkan)
df_cleaned

df_cleaned = df_cleaned.reset_index(drop=True)

"""### **Data Visualization**

**Jumlah Film Berdasarkan Distribusi Rating Film**
"""

# Visualisasi jumlah film per rating (0-10)
sns.histplot(df_cleaned['rating'], bins=10, kde=True)
plt.title('Distribusi Rating Film')
plt.xlabel('Rating')
plt.ylabel('Jumlah Film')
plt.show()

"""**Jumlah Film Berdasarkan Tahun Rilis**"""

# Visualisasi Jumlah film per tahun rilis
film_per_tahun = df_cleaned['release_year'].value_counts().sort_index()
film_per_tahun.plot(kind='line', figsize=(10,5), marker='o')
plt.title('Jumlah Film per Tahun Rilis')
plt.xlabel('Tahun Rilis')
plt.ylabel('Jumlah Film')
plt.grid()
plt.show()

"""**10 Genre dengan Jumlah Film Terbanyak**"""

# Visualisasi 10 genre dengan jumlah film terbanyak
plt.figure(figsize=(10,6))
sns.barplot(data=genre_df.head(10), y='Genre', x='Jumlah', palette='viridis')
plt.title('10 Genre dengan Jumlah Film Terbanyak')
plt.xlabel('Jumlah Film')
plt.ylabel('Genre')
plt.tight_layout()
plt.show()

"""**Rating vs Popularity Scatter Plot**"""

# Melihat pola hubungan antara skor popularitas dan rating film
plt.figure(figsize=(10,6))
sns.scatterplot(data=df_cleaned, x='rating', y='popularity', alpha=0.5)
plt.title('Rating vs Popularitas Film')
plt.xlabel('Rating')
plt.ylabel('Popularitas')
plt.grid(True)
plt.show()

"""## **2. Data Preparation**

### **Mapping**
"""

# Mapping mood berdasarkan genre
def genre_to_mood(genres_str):
    if 'Science Fiction' in genres_str or 'Fantasy' in genres_str:
        return 'Imaginative'
    elif 'Romance' in genres_str:
        return 'Romantic'
    elif 'Documentary' in genres_str:
        return 'Insightful'
    elif 'Action' in genres_str or 'Adventure' in genres_str:
        return 'Energetic'
    elif 'Drama' in genres_str or 'Family' in genres_str:
        return 'Emotional'
    elif 'Horror' in genres_str or 'Thriller' in genres_str or 'Mystery' in genres_str:
        return 'Thrilling'
    elif 'Comedy' in genres_str or 'Animation' in genres_str:
        return 'Cheerful'
    elif 'Science Fiction' in genres_str or 'Fantasy' in genres_str:
        return 'Imaginative'

    else:
        return 'Neutral'

df_cleaned['mood'] = df_cleaned['genre_clean'].apply(genre_to_mood)

df_cleaned

# Hitung jumlah film per mood
mood_counts = df_cleaned['mood'].value_counts()

# Tampilkan hasil
print(mood_counts)

# Visualisasi jumlah film berdasarkan mood
plt.figure(figsize=(8, 8))
mood_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff','#99ff99','#ffcc99', '#ff6666', '#c2c2f0'])
plt.title('Jumlah Film per Mood')
plt.ylabel('')
plt.show()

"""### **Multilabel Binarization**"""

mlb = MultiLabelBinarizer()
genre_ohe = mlb.fit_transform(df_cleaned['genre_clean'])
genre_df = pd.DataFrame(genre_ohe, columns=mlb.classes_)

"""### **Feature Engineering**"""

features = pd.concat([
    df_cleaned[['release_year', 'popularity', 'rating']].reset_index(drop=True),
    genre_df.reset_index(drop=True)
], axis=1)

"""### **Standardization**"""

scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

"""### **Label Encoding**"""

le = LabelEncoder()
labels = le.fit_transform(df_cleaned['mood'])

"""### **One-Hot Encoding for Labels**"""

labels_ohe = tf.keras.utils.to_categorical(labels)

"""### **Data Splitting**"""

X_train, X_test, y_train, y_test = train_test_split(
    features_scaled, labels_ohe, test_size=0.2, random_state=42)

"""## **3. Modelling**"""

model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dense(y_train.shape[1], activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# Training
history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)

"""## **4. Evaluation**

### **Test Accuracy Score**
"""

test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Akurasi pada test set: {test_accuracy * 100:.2f}%")

"""### **Classification Report**"""

# Prediksi
y_pred = model.predict(X_test)

# Konversi dari one-hot encoding ke label asli
y_pred_labels = np.argmax(y_pred, axis=1)
y_true_labels = np.argmax(y_test, axis=1)

# Label kelas (nama mood dari LabelEncoder)
class_names = le.classes_

# Tampilkan classification report
print(classification_report(y_true_labels, y_pred_labels, target_names=class_names))

"""### **Confusion Matrix**"""

# Confusion matrix
cm = confusion_matrix(y_true_labels, y_pred_labels)

# Visualisasi
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.show()

"""### **Model Saving**"""

model.save("sistem_rekomendasi_model.h5")

import pickle
with open("scaler.pkl", "wb") as f: pickle.dump(scaler, f)
with open("mlb.pkl", "wb") as f: pickle.dump(mlb, f)
with open("label_encoder.pkl", "wb") as f: pickle.dump(le, f)

df_cleaned.to_csv('dataset_fix.csv', index=False)